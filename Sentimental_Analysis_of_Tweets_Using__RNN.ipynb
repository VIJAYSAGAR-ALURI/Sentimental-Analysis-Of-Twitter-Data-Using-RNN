{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VIJAYSAGAR-ALURI/Sentimental-Analysis-Of-Twitter-Data-Using-RNN/blob/main/Sentimental_Analysis_of_Tweets_Using__RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "DEOLVam5XJg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "0y1nKW_fXLTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/Tweets.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(csv_path, encoding='utf-8', engine='python', on_bad_lines='skip')\n",
        "except UnicodeDecodeError:\n",
        "    df = pd.read_csv(csv_path, encoding='ISO-8859-1', engine='python', on_bad_lines='skip')\n",
        "\n",
        "if all(isinstance(col, int) for col in df.columns):\n",
        "    if df.shape[1] >= 6:\n",
        "        df.columns = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "    else:\n",
        "        df.columns = [f\"col_{i}\" for i in range(df.shape[1])]\n",
        "\n",
        "print(\"âœ… Columns in dataset:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55WMEGNyXOD1",
        "outputId": "b2c42838-4f20-4078-c296-d9e23f95b3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Columns in dataset: ['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence', 'airline', 'airline_sentiment_gold', 'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord', 'tweet_created', 'tweet_location', 'user_timezone']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_text_column(df):\n",
        "    text_candidates = [\"text\", \"tweet\", \"review\", \"comment\", \"message\", \"content\", \"body\"]\n",
        "    for c in text_candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object' and df[col].astype(str).str.len().mean() > 20:\n",
        "            return col\n",
        "    return df.columns[-1]\n",
        "\n",
        "def detect_label_column(df):\n",
        "    label_candidates = [\"sentiment\", \"label\", \"emotion\", \"target\", \"category\", \"airline_sentiment\", \"polarity\"]\n",
        "    for c in label_candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'object' and df[col].nunique() < 20:\n",
        "            return col\n",
        "    return df.columns[0]\n",
        "\n",
        "TEXT_COLUMN = detect_text_column(df)\n",
        "LABEL_COLUMN = detect_label_column(df)\n",
        "\n",
        "print(f\"âœ… Using Text Column: {TEXT_COLUMN}\")\n",
        "print(f\"âœ… Using Label Column: {LABEL_COLUMN}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llHD3TM7XRMv",
        "outputId": "62ac04d6-97d8-4066-c5a8-ad08d08e34e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using Text Column: text\n",
            "âœ… Using Label Column: airline_sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = {\n",
        "    \"a\",\"an\",\"the\",\"and\",\"or\",\"is\",\"am\",\"are\",\"was\",\"were\",\"in\",\"on\",\"at\",\"to\",\"of\",\"for\",\"this\",\"that\",\"it\",\"be\",\"as\",\n",
        "    \"with\",\"by\",\"from\",\"but\",\"if\",\"then\",\"so\",\"too\",\"very\",\"can\",\"will\",\"just\",\"do\",\"does\",\"did\",\"have\",\"has\",\"had\",\"not\",\n",
        "    \"no\",\"yes\",\"you\",\"i\",\"me\",\"my\",\"we\",\"us\",\"our\",\"they\",\"them\",\"their\",\"he\",\"she\",\"his\",\"her\"\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "    text = re.sub(r\"@\\w+|#\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = \" \".join([w for w in text.split() if w not in stop_words])\n",
        "    return text.strip()\n",
        "\n",
        "df[\"clean_text\"] = df[TEXT_COLUMN].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "JV7xSRBRXUub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\n",
        "    \"positive\": \"Happy\", \"negative\": \"Sad\", \"neutral\": \"Neutral\",\n",
        "    \"angry\": \"Angry\", \"frustrated\": \"Angry\", \"excited\": \"Excited\",\n",
        "    \"surprised\": \"Surprised\", \"relaxed\": \"Relaxed\", \"disgusted\": \"Disgusted\",\n",
        "    \"fear\": \"Fearful\", \"joy\": \"Happy\", \"sadness\": \"Sad\", \"happiness\": \"Happy\",\n",
        "    \"anger\": \"Angry\", \"0\": \"Sad\", \"1\": \"Neutral\", \"2\": \"Happy\", \"4\": \"Happy\"\n",
        "}\n",
        "\n",
        "unique_labels = df[LABEL_COLUMN].astype(str).str.lower().unique()\n",
        "for lbl in unique_labels:\n",
        "    if lbl not in label_mapping:\n",
        "        label_mapping[lbl] = lbl.capitalize()\n",
        "\n",
        "df[\"emotion\"] = df[LABEL_COLUMN].astype(str).str.lower().map(label_mapping).fillna(\"Neutral\")"
      ],
      "metadata": {
        "id": "WvpYQmgaXYVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df[\"label_enc\"] = le.fit_transform(df[\"emotion\"])\n",
        "num_classes = len(le.classes_)\n",
        "print(\"âœ… Detected Emotion Classes:\", le.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vn-XGciXbng",
        "outputId": "e5daa67d-e0d8-4e76-86fc-0d97eafe61aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Detected Emotion Classes: ['Angry' 'Disgusted' 'Excited' 'Happy' 'Neutral' 'Relaxed' 'Sad'\n",
            " 'Surprised']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 80\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df[\"clean_text\"])\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df[\"clean_text\"])\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y = df[\"label_enc\"].values\n"
      ],
      "metadata": {
        "id": "ofKrvUjEXeiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(np.unique(y)) > 1:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = X, X, y, y\n"
      ],
      "metadata": {
        "id": "X3bdWOujXia-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(MAX_VOCAB_SIZE, 128, input_length=MAX_SEQUENCE_LENGTH),\n",
        "    SimpleRNN(256, activation='tanh'),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "nLE3D-HqXl_i",
        "outputId": "c593c747-0cda-459d-fae6-3907d332d7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=64, verbose=2, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNsxe0GnXpo9",
        "outputId": "74aa8703-cbf2-4ab0-d018-3281d87e3e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "149/149 - 2s - 12ms/step - accuracy: 0.9629 - loss: 0.1211 - val_accuracy: 0.7155 - val_loss: 1.4599\n",
            "Epoch 2/10\n",
            "149/149 - 2s - 11ms/step - accuracy: 0.9717 - loss: 0.0993 - val_accuracy: 0.7104 - val_loss: 1.6278\n",
            "Epoch 3/10\n",
            "149/149 - 2s - 11ms/step - accuracy: 0.9670 - loss: 0.1118 - val_accuracy: 0.7218 - val_loss: 1.4572\n",
            "Epoch 4/10\n",
            "149/149 - 2s - 12ms/step - accuracy: 0.9761 - loss: 0.0784 - val_accuracy: 0.7272 - val_loss: 1.4669\n",
            "Epoch 5/10\n",
            "149/149 - 2s - 10ms/step - accuracy: 0.9725 - loss: 0.0897 - val_accuracy: 0.6932 - val_loss: 1.4692\n",
            "Epoch 6/10\n",
            "149/149 - 2s - 10ms/step - accuracy: 0.9748 - loss: 0.0795 - val_accuracy: 0.7063 - val_loss: 1.5924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d43885aaa80>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = model.predict(X, verbose=0)\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "df[\"Predicted_Emotion\"] = [le.classes_[i] for i in pred_classes]\n",
        "df[\"Confidence\"] = np.max(pred_probs, axis=1)\n",
        "\n",
        "def map_sentiment(e):\n",
        "    if e in [\"Happy\", \"Excited\", \"Relaxed\", \"Joyful\"]:\n",
        "        return \"Positive\"\n",
        "    elif e in [\"Sad\", \"Angry\", \"Disgusted\", \"Fearful\"]:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "df[\"Sentiment\"] = df[\"Predicted_Emotion\"].apply(map_sentiment)\n",
        "\n",
        "suggestions = {\n",
        "    \"Happy\": \"Keep spreading positivity!\",\n",
        "    \"Neutral\": \"Stay calm and observe.\",\n",
        "    \"Sad\": \"It's okay to feel sad sometimes. Talk to someone.\",\n",
        "    \"Angry\": \"Try taking deep breaths. Calm helps.\",\n",
        "    \"Excited\": \"Amazing! Use your energy wisely.\",\n",
        "    \"Surprised\": \"Wow! Stay curious.\",\n",
        "    \"Relaxed\": \"Peaceful and calmâ€”keep it up.\",\n",
        "    \"Disgusted\": \"Step away and do something you enjoy.\",\n",
        "    \"Fearful\": \"Remember, courage grows through action.\"\n",
        "}\n",
        "\n",
        "df[\"Suggestion\"] = df[\"Predicted_Emotion\"].map(lambda e: suggestions.get(e, \"Take care of yourself.\"))"
      ],
      "metadata": {
        "id": "dKiaCQ88XtVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===============================\")\n",
        "print(\"ğŸ¯ SAMPLE PREDICTIONS FROM DATASET:\")\n",
        "print(\"===============================\\n\")\n",
        "print(df[[TEXT_COLUMN, \"emotion\", \"Predicted_Emotion\", \"Sentiment\", \"Confidence\", \"Suggestion\"]].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqt-bIOKXyGo",
        "outputId": "f87da7b1-61cd-4500-c5e0-3ba93f4bc746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===============================\n",
            "ğŸ¯ SAMPLE PREDICTIONS FROM DATASET:\n",
            "===============================\n",
            "\n",
            "                                                text  emotion  \\\n",
            "0                @VirginAmerica What @dhepburn said.  Neutral   \n",
            "1  @VirginAmerica plus you've added commercials t...    Happy   \n",
            "2  @VirginAmerica I didn't today... Must mean I n...  Neutral   \n",
            "3  @VirginAmerica it's really aggressive to blast...      Sad   \n",
            "4  @VirginAmerica and it's a really big bad thing...      Sad   \n",
            "5  @VirginAmerica seriously would pay $30 a fligh...      Sad   \n",
            "6  @VirginAmerica yes, nearly every time I fly VX...    Happy   \n",
            "7  @VirginAmerica Really missed a prime opportuni...  Neutral   \n",
            "8    @virginamerica Well, I didn'tâ€¦but NOW I DO! :-D    Happy   \n",
            "9  @VirginAmerica it was amazing, and arrived an ...    Happy   \n",
            "\n",
            "  Predicted_Emotion Sentiment  Confidence  \\\n",
            "0           Neutral   Neutral    0.756450   \n",
            "1             Happy  Positive    0.999325   \n",
            "2           Neutral   Neutral    0.983795   \n",
            "3               Sad  Negative    0.999954   \n",
            "4               Sad  Negative    0.998401   \n",
            "5               Sad  Negative    0.999680   \n",
            "6           Neutral   Neutral    0.768130   \n",
            "7           Neutral   Neutral    0.999127   \n",
            "8             Happy  Positive    0.998824   \n",
            "9             Happy  Positive    0.996534   \n",
            "\n",
            "                                          Suggestion  \n",
            "0                             Stay calm and observe.  \n",
            "1                         Keep spreading positivity!  \n",
            "2                             Stay calm and observe.  \n",
            "3  It's okay to feel sad sometimes. Talk to someone.  \n",
            "4  It's okay to feel sad sometimes. Talk to someone.  \n",
            "5  It's okay to feel sad sometimes. Talk to someone.  \n",
            "6                             Stay calm and observe.  \n",
            "7                             Stay calm and observe.  \n",
            "8                         Keep spreading positivity!  \n",
            "9                         Keep spreading positivity!  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/Predicted_Output.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"\\nâœ… Results saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FNni-9lX3eS",
        "outputId": "532a7c17-0e90-4c86-e494-891d31a60200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Results saved to: /content/Predicted_Output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "POS_WORDS = {\"happy\", \"joy\", \"pleased\", \"delighted\", \"glad\", \"awesome\", \"great\", \"amazing\", \"love\"}\n",
        "NEG_WORDS = {\"sad\", \"unhappy\", \"depressed\", \"miserable\", \"hate\", \"angry\", \"upset\", \"terrible\", \"bad\"}\n",
        "\n",
        "def contains_negation_before(word, text, window=3):\n",
        "    tokens = text.split()\n",
        "    try:\n",
        "        idx = tokens.index(word)\n",
        "    except ValueError:\n",
        "        return False\n",
        "    start = max(0, idx - window)\n",
        "    context = tokens[start:idx]\n",
        "    for w in context:\n",
        "        if w in {\"not\", \"no\", \"never\", \"n't\"}:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def rule_based_prediction(cleaned):\n",
        "    tokens = cleaned.split()\n",
        "    for t in tokens:\n",
        "        if t in POS_WORDS:\n",
        "            if contains_negation_before(t, cleaned):\n",
        "                return \"Sad\", \"Negative\", 0.9\n",
        "            return \"Happy\", \"Positive\", 0.95\n",
        "        if t in NEG_WORDS:\n",
        "            if contains_negation_before(t, cleaned):\n",
        "                return \"Happy\", \"Positive\", 0.9\n",
        "            return \"Sad\", \"Negative\", 0.95\n",
        "    return None\n",
        "\n",
        "CONF_THRESH = 0.65\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nğŸ’¬ Enter a sentence to analyze sentiment (or type 'exit' to stop): \").strip()\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"ğŸ‘‹ Exiting sentiment analysis.\")\n",
        "        break\n",
        "\n",
        "    cleaned_input = clean_text(user_input)\n",
        "    if not cleaned_input:\n",
        "        print(\"âš ï¸ Please enter a valid sentence.\")\n",
        "        continue\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([cleaned_input])\n",
        "    padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "    pred = model.predict(padded, verbose=0)[0]\n",
        "    pred_class_idx = int(np.argmax(pred))\n",
        "    pred_class = le.classes_[pred_class_idx]\n",
        "    confidence = float(pred[pred_class_idx])\n",
        "\n",
        "    # Apply rule-based correction only if confidence is low\n",
        "    if confidence < CONF_THRESH:\n",
        "        rule = rule_based_prediction(cleaned_input)\n",
        "        if rule:\n",
        "            emotion, sentiment, confidence = rule\n",
        "        else:\n",
        "            emotion = pred_class\n",
        "            sentiment = map_sentiment(pred_class)\n",
        "    else:\n",
        "        emotion = pred_class\n",
        "        sentiment = map_sentiment(pred_class)\n",
        "\n",
        "    suggestion = suggestions.get(emotion, \"Take care of yourself.\")\n",
        "\n",
        "    print(\"\\n===============================\")\n",
        "    print(f\"ğŸ§  Emotion Detected: {emotion}\")\n",
        "    print(f\"ğŸ’­ Sentiment: {sentiment}\")\n",
        "    print(f\"ğŸ“Š Confidence: {confidence:.2f}\")\n",
        "    print(f\"ğŸ’¡ Suggestion: {suggestion}\")\n",
        "    print(\"===============================\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLf2DB8sX6Te",
        "outputId": "315e7b00-aa5c-4536-9856-26dd40a2fdee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ’¬ Enter a sentence to analyze sentiment (or type 'exit' to stop): hi\n",
            "\n",
            "===============================\n",
            "ğŸ§  Emotion Detected: Neutral\n",
            "ğŸ’­ Sentiment: Neutral\n",
            "ğŸ“Š Confidence: 0.98\n",
            "ğŸ’¡ Suggestion: Stay calm and observe.\n",
            "===============================\n",
            "\n",
            "\n",
            "ğŸ’¬ Enter a sentence to analyze sentiment (or type 'exit' to stop): I am happy to meet my friends, but sad to go to college to meet them.\n",
            "\n",
            "===============================\n",
            "ğŸ§  Emotion Detected: Neutral\n",
            "ğŸ’­ Sentiment: Neutral\n",
            "ğŸ“Š Confidence: 1.00\n",
            "ğŸ’¡ Suggestion: Stay calm and observe.\n",
            "===============================\n",
            "\n",
            "\n",
            "ğŸ’¬ Enter a sentence to analyze sentiment (or type 'exit' to stop): exit\n",
            "ğŸ‘‹ Exiting sentiment analysis.\n"
          ]
        }
      ]
    }
  ]
}